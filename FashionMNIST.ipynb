{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYmNzFNI_ne4",
        "outputId": "83a73c26-e712-43a9-f6d8-2a5c67a5f5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wrN9NmwD8xUk2TXqVqk661ekyHm_2wFB\n",
            "To: /content/test_images.npy\n",
            "100% 7.84M/7.84M [00:00<00:00, 82.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y5dsLErTYpyavcaSBE2sVm5AMBGGFJq5\n",
            "To: /content/test_labels.npy\n",
            "100% 10.1k/10.1k [00:00<00:00, 23.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rsmxEm0mZzVXpbE3HYERbRn1jxDmEvFX\n",
            "To: /content/train_images.npy\n",
            "100% 47.0M/47.0M [00:00<00:00, 121MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YthtVP80XjD7afCiL7FHZsmbjWgnuSln\n",
            "To: /content/train_labels.npy\n",
            "100% 60.1k/60.1k [00:00<00:00, 37.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1wrN9NmwD8xUk2TXqVqk661ekyHm_2wFB\n",
        "!gdown 1Y5dsLErTYpyavcaSBE2sVm5AMBGGFJq5\n",
        "!gdown 1rsmxEm0mZzVXpbE3HYERbRn1jxDmEvFX\n",
        "!gdown 1YthtVP80XjD7afCiL7FHZsmbjWgnuSln"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86OAzyq8TULa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq1zkXKZgvFb"
      },
      "outputs": [],
      "source": [
        "cfg = {\n",
        "    'lr': 0.01,\n",
        "    'weight_decay': 0.0001, # prevents overfitting\n",
        "    'momentum': 0.9,\n",
        "    'nesterov': True,\n",
        "    'epochs': 20,\n",
        "    'batch_size': 64,\n",
        "    'log_every': 1,\n",
        "    'val_every': 1,\n",
        "    'num_workers': 4,\n",
        "    'patience': 5, # This parameter determines the number of epochs with no improvement in the monitored metric (test set accuracy) after which the learning rate will be reduced. If the monitored metric does not improve for the specified number of epochs, the scheduler considers it as a lack of progress and reduces the learning rate.\n",
        "    'lr_decay': 0.5 # This parameter controls the factor by which the learning rate will be reduced. For example, if factor=0.1, the learning rate will be reduced by a factor of 0.1 when the specified patience is reached.\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "sGJujSYnm456",
        "outputId": "425c3a47-f346-4d58-d3a1-6b728c2ab24f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Define your data path (the directory containing the 4 np array files)\n",
        "DATA_PATH = \"/content\"\n",
        "\n",
        "class FMNIST(Dataset):\n",
        "    def __init__(self, set_name): # set_name is either test or train\n",
        "        super().__init__()\n",
        "        # TODO: Retrieve all the images and the labels, and store them\n",
        "        # as class variables. Maintaing any other class variables that\n",
        "        # you might need for the other class methods. Note that the\n",
        "        # methods depends on the set (train or test) and thus maintaining\n",
        "        # that is essential.\n",
        "        self.set_name = set_name\n",
        "        # Retrieve the file paths\n",
        "        images_file = os.path.join(DATA_PATH, f'{set_name}_images.npy')\n",
        "        labels_file = os.path.join(DATA_PATH, f'{set_name}_labels.npy')\n",
        "\n",
        "        # Load the dataset files\n",
        "        self.images_array = np.load(images_file)\n",
        "        self.images = torch.from_numpy(np.load(images_file).astype(np.float32) / 255.0)  # Scale images to [0, 1]\n",
        "        self.labels = torch.from_numpy(np.load(labels_file))\n",
        "        self.n_samples = self.images.shape[0]\n",
        "        #\n",
        "\n",
        "    def __len__(self): # returns total number of samples in the dataset\n",
        "        # TODO: Complete this\n",
        "        return self.n_samples\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # TODO: Complete this\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        return image,label\n",
        "\n",
        "\n",
        "\n",
        "def get_data_loader(set_name):\n",
        "    # TODO: Create the dataset class tailored to the set (train or test)\n",
        "    # provided as argument. Use it to create a dataloader. Use the appropriate\n",
        "    # hyper-parameters from cfg\n",
        "    dataset = FMNIST(set_name)\n",
        "    dataLoader = DataLoader(dataset=dataset, batch_size=cfg[\"batch_size\"],shuffle=True,num_workers=cfg[\"num_workers\"])\n",
        "    return dataLoader\n",
        "\n",
        "\n",
        "dataset = FMNIST(\"test\")\n",
        "plt.imshow(dataset.images_array[10], cmap = 'gray')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MDR9kJhppfD"
      },
      "outputs": [],
      "source": [
        "def xavier_init(param):\n",
        "    # NOTE: Not for Vanilla Classifier\n",
        "    # TODO: Complete this to initialize the weights\n",
        "    if param.dim() > 1: # for weights\n",
        "        torch.nn.init.xavier_normal_(param)\n",
        "    else: # for bias\n",
        "        param.data.fill_(0)\n",
        "\n",
        "\n",
        "def zero_init(param):\n",
        "    # NOTE: Not for Vanilla Classifier\n",
        "    # TODO: Complete this to initialize the weights\n",
        "\n",
        "    if param.dim() > 1: # for weights\n",
        "        torch.nn.init.zeros_(param)\n",
        "    else: # for bias\n",
        "        param.data.fill_(0)\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        # TODO: Define the model architecture here\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(784, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 10),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "        # NOTE: Not for Vanilla Classsifier\n",
        "        # TODO: Initalize weights by calling the\n",
        "        # init_weights method\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "           if isinstance(m, nn.Linear):\n",
        "            xavier_init(m.weight)\n",
        "            xavier_init(m.bias)\n",
        "\n",
        "\n",
        "    # def _init_weights(self, module):\n",
        "    #     if isinstance(module, nn.Linear):\n",
        "    #         xavier_init(module.weight)\n",
        "    #         xavier_init(module.bias)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Define the forward function of your model\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def save(self, ckpt_path):\n",
        "        # TODO: Save the checkpoint of the model\n",
        "        torch.save(self.state_dict(), ckpt_path)\n",
        "\n",
        "    def load(self, ckpt_path):\n",
        "        # TODO: Load the checkpoint of the model\n",
        "        self.load_state_dict(torch.load(ckpt_path))\n",
        "        # self.eval()\n",
        "\n",
        "# network = Network()\n",
        "# # print(network)\n",
        "\n",
        "# for name, param in network.named_parameters():\n",
        "#     print(f\"Layer: {name}, Size: {param.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "qJIRtYrgqbCH",
        "outputId": "f661f26c-d007-4cc7-cd47-9fd39a901120"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-05b3d2d347f8>\u001b[0m in \u001b[0;36m<cell line: 140>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# Run the training!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-05b3d2d347f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, test_loader, logger)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Run the network on the entire train dataset. Return the average train loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Note that we don't have to calculate the accuracy on the train set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# TODO: Get the current learning rate by calling get_lr() and log it to tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-05b3d2d347f8>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(net, epoch, loader, optimizer, criterion, logger, scheduler, train)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Iterate over the loader and calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Clear the gradients if training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSocketClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mSocketClient\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from termcolor import cprint\n",
        "except ImportError:\n",
        "    cprint = None\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "def log_print(text, color=None, on_color=None, attrs=None):\n",
        "    if cprint is not None:\n",
        "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
        "    else:\n",
        "        print(text)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    #TODO: Returns the current Learning Rate being used by\n",
        "    # the optimizer\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "'''\n",
        "Use the average meter to keep track of average of the loss or\n",
        "the test accuracy! Just call the update function, providing the\n",
        "quantities being added, and the counts being added\n",
        "'''\n",
        "class AvgMeter():\n",
        "    def __init__(self):\n",
        "        self.qty = 0\n",
        "        self.cnt = 0\n",
        "\n",
        "    def update(self, increment, count):\n",
        "        self.qty += increment\n",
        "        self.cnt += count\n",
        "\n",
        "    def get_avg(self):\n",
        "        if self.cnt == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return self.qty/self.cnt\n",
        "\n",
        "\n",
        "def run(net, epoch, loader, optimizer, criterion, logger, scheduler, train=True):\n",
        "    # Initialize the different Avg Meters for tracking loss and accuracy (if test)\n",
        "    loss_meter = AvgMeter()\n",
        "    acc_meter = AvgMeter()\n",
        "\n",
        "    # Set the network to train or eval mode based on the train flag\n",
        "    if train:\n",
        "        net.train()\n",
        "    else:\n",
        "        net.eval()\n",
        "\n",
        "    # Iterate over the loader and calculate the loss\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        # Clear the gradients if training\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = net(data)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Update the loss meter\n",
        "        loss_meter.update(loss.item(), 1) # or is it loss_meter.update(loss.item(), data.shape[0])?\n",
        "\n",
        "        if train:\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        else:\n",
        "            # Calculate the accuracy\n",
        "            predicted_labels = output.argmax(dim=1)\n",
        "            correct_predictions = (predicted_labels == target).sum().item()\n",
        "            accuracy = correct_predictions / len(target)\n",
        "            acc_meter.update(accuracy, 1) #doubt\n",
        "\n",
        "    # Log the training/testing loss using tensorboard\n",
        "    logger.add_scalar('Loss/{}'.format('Train' if train else 'Test'), loss_meter.get_avg(), epoch)\n",
        "\n",
        "    # Return the average loss and accuracy (if test set)\n",
        "    if train:\n",
        "        return loss_meter.get_avg(), None\n",
        "    else:\n",
        "        return loss_meter.get_avg(), acc_meter.get_avg()\n",
        "\n",
        "\n",
        "\n",
        "def train(net, train_loader, test_loader, logger):\n",
        "    # TODO: Define the SGD optimizer here. Use hyper-parameters from cfg\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr = cfg['lr'], momentum=cfg['momentum'], weight_decay=cfg['weight_decay'], nesterov=cfg['nesterov'])\n",
        "    # TODO: Define the criterion (Objective Function) that you will be using\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # TODO: Define the ReduceLROnPlateau scheduler for annealing the learning rate\n",
        "    # The ReduceLROnPlateau scheduler monitors a specified metric (e.g., test set accuracy) and reduces the\n",
        "    # learning rate when the monitored metric stops improving. It provides a mechanism to gradually\n",
        "    # decrease the learning rate, potentially allowing the model to converge to a better solution.\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=cfg['lr_decay'], patience=cfg['patience'], verbose=True)\n",
        "    # mode='max' as scheduler will think that there is improvement if increase in test set accuracy\n",
        "\n",
        "    for i in range(cfg['epochs']):\n",
        "        # Run the network on the entire train dataset. Return the average train loss\n",
        "        # Note that we don't have to calculate the accuracy on the train set.\n",
        "        loss, _ = run(net, i, train_loader, optimizer, criterion, logger, scheduler)\n",
        "\n",
        "        # TODO: Get the current learning rate by calling get_lr() and log it to tensorboard\n",
        "        current_lr = get_lr(optimizer)\n",
        "        logger.add_scalar('Learning Rate',current_lr,i)\n",
        "\n",
        "        # Logs the training loss on the screen, while training\n",
        "        if i % cfg['log_every'] == 0:\n",
        "            log_text = \"Epoch: [%d/%d], Training Loss:%2f\" % (i+1, cfg['epochs'], loss)\n",
        "            log_print(log_text, color='green', attrs=['bold'])\n",
        "\n",
        "        # Evaluate our model and add visualizations on tensorboard\n",
        "        if i % cfg['val_every'] == 0:\n",
        "            # TODO: HINT - you might need to perform some step before and after running the network\n",
        "            # on the test set\n",
        "            # Run the network on the test set, and get the loss and accuracy on the test set\n",
        "            loss, acc = run(net, i, test_loader, optimizer, criterion, logger, scheduler, train=False)\n",
        "            log_text = \"Epoch: %d, Test Accuracy:%2f\" % (i+1, acc*100.0)\n",
        "            log_print(log_text, color='red', attrs=['bold'])\n",
        "\n",
        "            # TODO: Perform a step on the scheduler, while using the Accuracy on the test set\n",
        "            scheduler.step(acc)\n",
        "\n",
        "            # TODO: Use tensorboard to log the Test Accuracy and also to perform visualization of the\n",
        "            # 2 weights of the first layer of the network!\n",
        "            first_layer_weights = net.model[1].weight.data\n",
        "            # Select two nodes for visualization\n",
        "            node1_weights = first_layer_weights[0].reshape(1, 28, 28)  # Assuming input size of 28x28\n",
        "            node2_weights = first_layer_weights[1].reshape(1, 28, 28)\n",
        "            # Log the weights as images\n",
        "            logger.add_image('First Layer Weights/Node1', node1_weights, i)\n",
        "            logger.add_image('First Layer Weights/Node2', node2_weights, i)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # TODO: Create a network object\n",
        "    net = Network()\n",
        "\n",
        "    # TODO: Create a tensorboard object for logging\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    # TODO: Create train data loader\n",
        "    train_loader = get_data_loader(\"train\")\n",
        "\n",
        "    # TODO: Create test data loader\n",
        "    test_loader = get_data_loader(\"test\")\n",
        "\n",
        "    # Run the training!\n",
        "    train(net, train_loader, test_loader, writer)\n",
        "    writer.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}